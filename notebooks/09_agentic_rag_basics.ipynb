{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG Basics\n",
    "\n",
    "**Build Your First Knowledge-Powered AI Agent**\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the world of **Retrieval-Augmented Generation (RAG)**! This notebook teaches you how to build AI agents that can access and reason over custom knowledge bases. By the end of this 10-minute tutorial, you'll have a working RAG system that enhances your agents with external knowledge.\n",
    "\n",
    "### 🎯 What You'll Learn\n",
    "\n",
    "In this tutorial, you will:\n",
    "- Understand what RAG is and why it's powerful\n",
    "- Build a local vector store using FAISS\n",
    "- Create embeddings with sentence transformers\n",
    "- Implement RAG tools for Strands agents\n",
    "- Build a knowledge-enabled agent\n",
    "- Test your agent with real queries\n",
    "\n",
    "### 🤔 What is RAG?\n",
    "\n",
    "**Retrieval-Augmented Generation** combines:\n",
    "- **Retrieval**: Finding relevant information from a knowledge base\n",
    "- **Generation**: Using that information to generate accurate responses\n",
    "\n",
    "Think of it as giving your agent a searchable library of information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Step 1: Installing Required Packages\n",
    "\n",
    "### Overview\n",
    "We'll install the necessary packages for RAG functionality. These include vector storage, embedding models, and the Strands framework.\n",
    "\n",
    "### 📚 What We're Installing\n",
    "- **sentence-transformers**: Creates embeddings from text\n",
    "- **faiss-cpu**: Facebook's vector similarity search library\n",
    "- **numpy**: For numerical operations\n",
    "- **strands-agents**: Our agent framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install sentence-transformers faiss-cpu numpy strands-agents -q\n",
    "\n",
    "# For document generation (optional)\n",
    "%pip install reportlab python-docx -q\n",
    "\n",
    "print(\"✅ All packages installed successfully!\")\n",
    "print(\"   Ready to build your RAG system! 🚀\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔑 Step 2: Setting Up AWS Bedrock\n",
    "\n",
    "### Hybrid Approach\n",
    "We'll use:\n",
    "- **Local storage** for our knowledge base (no cloud costs!)\n",
    "- **AWS Bedrock** for the powerful Claude LLM\n",
    "\n",
    "### 💡 Why This Approach?\n",
    "- Your documents stay private on your machine\n",
    "- Only pay for LLM usage, not storage\n",
    "- Fast local search with powerful cloud reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "import os\n",
    "\n",
    "# Configure AWS session\n",
    "# Note: Make sure you have AWS credentials configured\n",
    "session = boto3.Session(\n",
    "    profile_name='default'  # Use your AWS profile name\n",
    ")\n",
    "\n",
    "# Create a Bedrock model instance\n",
    "try:\n",
    "    bedrock_model = BedrockModel(\n",
    "        model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        boto_session=session\n",
    "    )\n",
    "    print(\"✅ AWS Bedrock configured successfully!\")\n",
    "    print(\"   Model: Claude 3.7 Sonnet\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error configuring Bedrock: {e}\")\n",
    "    print(\"   Please check your AWS credentials and Bedrock access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Step 3: Creating Sample Documents\n",
    "\n",
    "### Generate Knowledge Base Content\n",
    "Let's create some documents about the Strands framework for our RAG system to use. This ensures everyone has the same content to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our document generator\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "try:\n",
    "    from rag_document_generator import create_basic_documents\n",
    "    \n",
    "    # Create the documents\n",
    "    print(\"📝 Creating sample documents...\")\n",
    "    created_files = create_basic_documents()\n",
    "    \n",
    "    print(f\"\\n✅ Created {len(created_files)} documents:\")\n",
    "    for file in created_files:\n",
    "        print(f\"   - {file}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"⚠️  Could not import document generator. Creating documents manually...\")\n",
    "    \n",
    "    # Manual fallback\n",
    "    import os\n",
    "    os.makedirs('../rag_docs', exist_ok=True)\n",
    "    \n",
    "    # Create a simple document\n",
    "    with open('../rag_docs/strands_intro.txt', 'w') as f:\n",
    "        f.write(\"\"\"Strands is a powerful framework for building AI agents.\n",
    "It supports multiple models including AWS Bedrock, OpenAI, and local models.\n",
    "Agents can use tools to extend their capabilities.\n",
    "The framework is designed to be simple yet flexible.\"\"\")\n",
    "    \n",
    "    print(\"✅ Created fallback document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Step 4: Building the Local Vector Store\n",
    "\n",
    "### The RAG Engine\n",
    "Now we'll create the core RAG functionality:\n",
    "1. **Embeddings**: Convert text to numerical vectors\n",
    "2. **Vector Store**: Store and search these vectors\n",
    "3. **Retrieval**: Find relevant documents for queries\n",
    "\n",
    "### 🔍 How It Works\n",
    "- Text → Embeddings → Vector Store\n",
    "- Query → Embedding → Similarity Search → Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from typing import List, Dict, Any\n",
    "import pickle\n",
    "\n",
    "class LocalRAGStore:\n",
    "    \"\"\"A simple local RAG store using FAISS and sentence transformers.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"Initialize the RAG store with an embedding model.\"\"\"\n",
    "        print(f\"🚀 Loading embedding model: {model_name}...\")\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "        self.embedding_dim = 384  # Dimension for all-MiniLM-L6-v2\n",
    "        \n",
    "        # Storage\n",
    "        self.documents = []\n",
    "        self.metadata = []\n",
    "        self.index = faiss.IndexFlatL2(self.embedding_dim)\n",
    "        \n",
    "        print(\"✅ RAG store initialized!\")\n",
    "    \n",
    "    def add_documents(self, texts: List[str], metadata: List[Dict] = None):\n",
    "        \"\"\"Add documents to the store.\"\"\"\n",
    "        if not texts:\n",
    "            return\n",
    "        \n",
    "        # Store documents\n",
    "        self.documents.extend(texts)\n",
    "        \n",
    "        # Store metadata\n",
    "        if metadata:\n",
    "            self.metadata.extend(metadata)\n",
    "        else:\n",
    "            self.metadata.extend([{} for _ in texts])\n",
    "        \n",
    "        # Create embeddings\n",
    "        print(f\"📊 Creating embeddings for {len(texts)} documents...\")\n",
    "        embeddings = self.embedder.encode(texts, show_progress_bar=True)\n",
    "        \n",
    "        # Add to FAISS index\n",
    "        self.index.add(embeddings.astype('float32'))\n",
    "        \n",
    "        print(f\"✅ Added {len(texts)} documents to the knowledge base\")\n",
    "        print(f\"   Total documents: {len(self.documents)}\")\n",
    "    \n",
    "    def search(self, query: str, k: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for relevant documents.\"\"\"\n",
    "        # Embed the query\n",
    "        query_embedding = self.embedder.encode([query]).astype('float32')\n",
    "        \n",
    "        # Search in FAISS\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for i, (idx, distance) in enumerate(zip(indices[0], distances[0])):\n",
    "            if idx < len(self.documents):\n",
    "                results.append({\n",
    "                    'content': self.documents[idx],\n",
    "                    'metadata': self.metadata[idx],\n",
    "                    'score': float(distance),\n",
    "                    'rank': i + 1\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Create our RAG store\n",
    "print(\"🏗️ Creating local RAG store...\")\n",
    "rag_store = LocalRAGStore()\n",
    "print(\"\\n💡 The embedding model will download on first use (about 90MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📖 Step 5: Loading Documents into the Knowledge Base\n",
    "\n",
    "### Populating Our RAG System\n",
    "Now we'll load the documents we created earlier into our vector store. This creates a searchable knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load documents from the rag_docs directory\n",
    "rag_docs_path = Path('../rag_docs')\n",
    "documents_to_load = []\n",
    "metadata_list = []\n",
    "\n",
    "print(\"📁 Loading documents from rag_docs directory...\")\n",
    "\n",
    "# Read all text files\n",
    "for file_path in rag_docs_path.glob('*.txt'):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        documents_to_load.append(content)\n",
    "        metadata_list.append({\n",
    "            'source': file_path.name,\n",
    "            'type': 'text'\n",
    "        })\n",
    "        print(f\"   📄 Loaded: {file_path.name}\")\n",
    "\n",
    "# Read all markdown files\n",
    "for file_path in rag_docs_path.glob('*.md'):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        documents_to_load.append(content)\n",
    "        metadata_list.append({\n",
    "            'source': file_path.name,\n",
    "            'type': 'markdown'\n",
    "        })\n",
    "        print(f\"   📄 Loaded: {file_path.name}\")\n",
    "\n",
    "# Add documents to RAG store\n",
    "if documents_to_load:\n",
    "    print(f\"\\n🔄 Adding {len(documents_to_load)} documents to the knowledge base...\")\n",
    "    rag_store.add_documents(documents_to_load, metadata_list)\n",
    "else:\n",
    "    print(\"\\n⚠️  No documents found. Creating sample content...\")\n",
    "    \n",
    "    # Add some sample content\n",
    "    sample_docs = [\n",
    "        \"Strands is a framework for building AI agents. It supports tools and multiple models.\",\n",
    "        \"RAG stands for Retrieval-Augmented Generation. It helps agents access external knowledge.\",\n",
    "        \"AWS Bedrock provides access to Claude and other foundation models.\"\n",
    "    ]\n",
    "    \n",
    "    sample_metadata = [\n",
    "        {\"source\": \"sample_1\", \"type\": \"intro\"},\n",
    "        {\"source\": \"sample_2\", \"type\": \"rag\"},\n",
    "        {\"source\": \"sample_3\", \"type\": \"bedrock\"}\n",
    "    ]\n",
    "    \n",
    "    rag_store.add_documents(sample_docs, sample_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Step 6: Creating RAG Tools\n",
    "\n",
    "### Tools = Agent Superpowers\n",
    "We'll create tools that allow our agent to:\n",
    "1. Search the knowledge base\n",
    "2. Add new information\n",
    "\n",
    "### 🎯 Key Concepts\n",
    "- Tools must have type hints\n",
    "- Clear docstrings help the agent understand when to use each tool\n",
    "- Tools should handle errors gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strands import tool\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str, num_results: int = 3) -> str:\n",
    "    \"\"\"Search the knowledge base for relevant information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query\n",
    "        num_results: Number of results to return (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Formatted search results with sources\n",
    "    \"\"\"\n",
    "    # Perform the search\n",
    "    results = rag_store.search(query, k=num_results)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        source = result['metadata'].get('source', 'Unknown')\n",
    "        content = result['content'][:200] + \"...\" if len(result['content']) > 200 else result['content']\n",
    "        \n",
    "        formatted_results.append(\n",
    "            f\"[Source: {source}]\\n\"\n",
    "            f\"Content: {content}\\n\"\n",
    "            f\"Relevance Score: {result['score']:.2f}\"\n",
    "        )\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "@tool\n",
    "def add_to_knowledge_base(content: str, source: str = \"user_added\") -> str:\n",
    "    \"\"\"Add new information to the knowledge base.\n",
    "    \n",
    "    Args:\n",
    "        content: The information to add\n",
    "        source: The source of the information (default: \"user_added\")\n",
    "    \n",
    "    Returns:\n",
    "        Confirmation message\n",
    "    \"\"\"\n",
    "    # Add the document\n",
    "    rag_store.add_documents(\n",
    "        [content],\n",
    "        [{'source': source, 'type': 'user_added'}]\n",
    "    )\n",
    "    \n",
    "    return f\"Successfully added new information to the knowledge base from source: {source}\"\n",
    "\n",
    "print(\"🔧 RAG tools created successfully!\")\n",
    "print(\"   - search_knowledge_base: Find relevant information\")\n",
    "print(\"   - add_to_knowledge_base: Add new knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🤖 Step 7: Creating Your RAG-Enabled Agent\n",
    "\n",
    "### Bringing It All Together\n",
    "Now we'll create an agent that can:\n",
    "- Access the knowledge base\n",
    "- Answer questions using retrieved information\n",
    "- Learn new information when provided\n",
    "\n",
    "### 📋 Agent Instructions\n",
    "The system prompt is crucial - it tells the agent to always check the knowledge base first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG-enabled agent\n",
    "rag_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=\"\"\"You are a helpful AI assistant with access to a knowledge base about the Strands framework and AI agents.\n",
    "    \n",
    "    IMPORTANT INSTRUCTIONS:\n",
    "    1. Always search the knowledge base FIRST before answering questions\n",
    "    2. If you find relevant information, use it in your response and cite the source\n",
    "    3. If no relevant information is found, acknowledge this and provide your best answer\n",
    "    4. When users provide new information, add it to the knowledge base\n",
    "    5. Be helpful, accurate, and concise in your responses\n",
    "    \n",
    "    Remember: Your knowledge base is your primary source of truth!\"\"\",\n",
    "    tools=[search_knowledge_base, add_to_knowledge_base]\n",
    ")\n",
    "\n",
    "print(\"🎉 RAG-enabled agent created successfully!\")\n",
    "print(\"   Model: Claude 3.7 Sonnet (via Bedrock)\")\n",
    "print(\"   Knowledge Base: Local FAISS vector store\")\n",
    "print(\"   Tools: search_knowledge_base, add_to_knowledge_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💬 Step 8: Testing Your RAG Agent\n",
    "\n",
    "### Real-World Queries\n",
    "Let's test our agent with various questions to see how it uses the knowledge base. Watch how it searches for information before responding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Ask about Strands\n",
    "print(\"🔍 Test 1: Asking about Strands\")\n",
    "print(\"=\"*50)\n",
    "response = rag_agent(\"What is the Strands framework?\")\n",
    "print(f\"🤖 Agent: {response}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Ask about Python best practices\n",
    "print(\"🔍 Test 2: Asking about Python best practices\")\n",
    "print(\"=\"*50)\n",
    "response = rag_agent(\"What are some Python best practices for AI development?\")\n",
    "print(f\"🤖 Agent: {response}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Add new information\n",
    "print(\"📝 Test 3: Adding new information to the knowledge base\")\n",
    "print(\"=\"*50)\n",
    "response = rag_agent(\n",
    "    \"I want to add this information: RAG systems can significantly improve agent accuracy \"\n",
    "    \"by providing access to up-to-date and domain-specific information. They're especially \"\n",
    "    \"useful for technical documentation and customer support.\"\n",
    ")\n",
    "print(f\"🤖 Agent: {response}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Query the newly added information\n",
    "print(\"🔍 Test 4: Querying the newly added information\")\n",
    "print(\"=\"*50)\n",
    "response = rag_agent(\"What are RAG systems especially useful for?\")\n",
    "print(f\"🤖 Agent: {response}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Step 9: Understanding RAG Performance\n",
    "\n",
    "### Behind the Scenes\n",
    "Let's explore how our RAG system works and examine its performance characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the knowledge base\n",
    "print(\"📊 Knowledge Base Statistics:\")\n",
    "print(f\"   Total documents: {len(rag_store.documents)}\")\n",
    "print(f\"   Embedding dimension: {rag_store.embedding_dim}\")\n",
    "print(f\"   Index size: {rag_store.index.ntotal}\")\n",
    "\n",
    "# Test search performance\n",
    "import time\n",
    "\n",
    "test_queries = [\n",
    "    \"What is Strands?\",\n",
    "    \"How do I use tools?\",\n",
    "    \"AWS Bedrock setup\",\n",
    "    \"Python best practices\"\n",
    "]\n",
    "\n",
    "print(\"\\n⏱️  Search Performance Test:\")\n",
    "for query in test_queries:\n",
    "    start_time = time.time()\n",
    "    results = rag_store.search(query, k=3)\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"   Query: '{query}'\")\n",
    "    print(f\"   Time: {search_time*1000:.2f}ms\")\n",
    "    print(f\"   Top result: {results[0]['metadata']['source'] if results else 'No results'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 Step 10: Advanced Tips and Best Practices\n",
    "\n",
    "### Making the Most of RAG\n",
    "Here are key tips for building production-ready RAG systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎓 RAG BEST PRACTICES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "best_practices = {\n",
    "    \"📚 Document Preparation\": [\n",
    "        \"Chunk large documents into smaller pieces\",\n",
    "        \"Include metadata (source, date, category)\",\n",
    "        \"Keep chunks self-contained and meaningful\",\n",
    "        \"Remove duplicate information\"\n",
    "    ],\n",
    "    \"🔍 Search Optimization\": [\n",
    "        \"Use appropriate embedding models for your domain\",\n",
    "        \"Experiment with different k values for retrieval\",\n",
    "        \"Consider hybrid search (vector + keyword)\",\n",
    "        \"Implement re-ranking for better results\"\n",
    "    ],\n",
    "    \"🤖 Agent Design\": [\n",
    "        \"Always instruct agents to search first\",\n",
    "        \"Have agents cite their sources\",\n",
    "        \"Handle 'no results' cases gracefully\",\n",
    "        \"Allow agents to request more information\"\n",
    "    ],\n",
    "    \"⚡ Performance\": [\n",
    "        \"Use smaller models for simple domains\",\n",
    "        \"Cache frequent queries\",\n",
    "        \"Batch document additions\",\n",
    "        \"Consider GPU acceleration for embeddings\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, tips in best_practices.items():\n",
    "    print(f\"\\n{category}\")\n",
    "    for tip in tips:\n",
    "        print(f\"   • {tip}\")\n",
    "\n",
    "# Saving and loading the knowledge base\n",
    "print(\"\\n\\n💾 SAVING YOUR KNOWLEDGE BASE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "# Save the knowledge base\n",
    "import pickle\n",
    "\n",
    "def save_rag_store(rag_store, filepath='rag_store.pkl'):\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'documents': rag_store.documents,\n",
    "            'metadata': rag_store.metadata,\n",
    "            'index': faiss.serialize_index(rag_store.index)\n",
    "        }, f)\n",
    "\n",
    "# Load the knowledge base\n",
    "def load_rag_store(filepath='rag_store.pkl'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    # Reconstruct the store...\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "### 🏆 What You've Accomplished\n",
    "\n",
    "In just 10 minutes, you've:\n",
    "- ✅ Built a complete RAG system from scratch\n",
    "- ✅ Created a local vector store with FAISS\n",
    "- ✅ Implemented embedding-based search\n",
    "- ✅ Built RAG tools for Strands agents\n",
    "- ✅ Created a knowledge-enabled AI agent\n",
    "- ✅ Tested real-world queries\n",
    "\n",
    "### 🚀 What's Next?\\n\\nNow that you've mastered the basics of RAG, you're ready to explore:\\n1. **Advanced Document Processing** - Handle PDFs, Word docs, and more\\n2. **Persistent Storage** - Use ChromaDB for long-term knowledge\\n3. **Production Deployment** - Scale your RAG system\\n4. **Multi-Agent RAG** - Share knowledge between agents\\n\\n### 💡 Key Takeaways\\n\\n1. **RAG = Retrieval + Generation**: Combine search with AI generation\\n2. **Local Storage**: Keep your data private and costs low\\n3. **Powerful Cloud LLMs**: Use Bedrock for advanced reasoning\\n4. **Tools Enable RAG**: search_knowledge_base and add_to_knowledge_base\\n\\n### 📚 Resources\\n\\n- [Strands Documentation](https://strandsagents.com/0.1.x/)\\n- [FAISS Documentation](https://github.com/facebookresearch/faiss)\\n- [Sentence Transformers](https://www.sbert.net/)\\n\\n### 🌟 Challenge Yourself\\n\\nTry enhancing your RAG system by:\\n- Adding more documents to the knowledge base\\n- Experimenting with different embedding models\\n- Implementing document chunking for large files\\n- Creating specialized agents for different domains\\n\\nHappy building with RAG! 🚀🤖✨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
